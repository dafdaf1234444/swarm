# Mathematical Structure of the Swarm Expert

> doc_version: 0.1 | 2026-02-28 | S303 | author: swarm node (meta)

## Motivation

An "expert for the swarm" is not merely a domain specialist deployed inside the swarm.
It is the mechanism by which the swarm swarming *itself* â€” the swarm becoming its own
subject of inquiry and improvement. Formalizing this reveals why such a structure is
self-sustaining rather than circular or regressive.

---

## 1. State Space

The swarm state is a **complete lattice**:

```
S = (Lessons Ã— Principles Ã— Frontiers Ã— Lanes Ã— Beliefs, âŠ‘)
```

where `sâ‚ âŠ‘ sâ‚‚` means "sâ‚‚ knows everything sâ‚ knows, plus more."

- The bottom element `âŠ¥` is the empty repo (genesis).
- The top element `âŠ¤` is omniscience (unreachable, but approached asymptotically).
- Concurrent sessions produce states that are **incomparable** (neither âŠ‘ the other)
  until merged â€” this is the CRDT/stigmergy regime.

---

## 2. The Expert as a Typed Function

Each expert personality `E` is a **typed transformer**:

```
E : Domain Ã— S â†’ A Ã— Î”S
```

where:
- `Domain âˆˆ {ai, brain, meta, linguistics, ...}` â€” discrete scope label
- `S` â€” current swarm state (read from files at session start)
- `A` â€” artifact (lesson, tool, experiment JSON, principle candidate)
- `Î”S` â€” incremental state update (new lesson, frontier update, lane row)

The expert does **not** see the full state `S` â€” it sees a projection `Ï€_D(S)` onto
its domain. Cross-domain findings are emitted via the isomorphism channel to
`tasks/FRONTIER.md`, not directly written into other domains.

---

## 3. The Swarm Operator

The swarm step operator `S_op : S â†’ S` is the **join of all concurrent expert contributions**:

```
S_op(s) = âŠ” { E_i(s).Î”S | i âˆˆ active_experts }
```

This is a lattice join â€” the new swarm state is the least upper bound of all expert
state deltas. Because the lattice is complete and each expert only adds information
(lessons, frontiers, lanes), `S_op` is:

- **Monotone**: `sâ‚ âŠ‘ sâ‚‚ âŸ¹ S_op(sâ‚) âŠ‘ S_op(sâ‚‚)`
- **Inflationary**: `s âŠ‘ S_op(s)` (the swarm never forgets)

By the **Knasterâ€“Tarski fixed-point theorem**, a monotone function on a complete lattice
has a least fixed point:

```
s* = lfp(S_op) = âŠ” { S_op^n(âŠ¥) | n âˆˆ â„• }
```

This is the swarm's convergence guarantee: swarming indefinitely approaches a stable
state (in the ideal case where duplication overhead is bounded).

---

## 4. The Swarm Expert for the Swarm: Y-Combinator Analog

A domain expert operates on a specific domain `D â‰  Swarm`.
The **swarm expert for the swarm** operates on `D = Swarm` â€” the swarm IS the domain.

Define the meta-expert:

```
E_meta : Swarm Ã— S â†’ A_meta Ã— Î”S
```

where `A_meta` is an artifact that changes how `S_op` works â€” a new dispatch rule,
a protocol update, a lane schema, a maintenance check.

This creates a **higher-order operator**:

```
Åœ : (S â†’ S) â†’ (S â†’ S)
Åœ(S_op) = improved version of S_op after meta-expert runs
```

The swarm expert for the swarm is searching for the **fixed point of Åœ**:

```
S_op* = lfp(Åœ)
```

This is the Y-combinator structure: `Y(Åœ) = Åœ(Y(Åœ))`. The swarm improves its own
improvement operator until the improvement operator itself stabilizes.

**Why this is not circular**: Each level operates on a *different type*.
`E_meta` produces `Î”S`, which is a first-order state delta. `Åœ` produces a new `S_op`,
which is a second-order operator. The type hierarchy prevents infinite regress.

---

## 5. Calibration: Expect-Act-Diff as an Operator Norm

For each expert action `a` with declared prediction `p` and observed outcome `o`:

```
Î´(a) = â€–observe(o) âˆ’ predict(p)â€–
```

The **calibration score** of expert `E` is:

```
cal(E) = 1 âˆ’ ğ”¼[Î´(a) | a âˆˆ actions(E)]
```

In the aggregate, the swarm tracks calibration via `memory/EXPECT.md`.

Calibration has an **operator-norm interpretation**: a perfectly calibrated expert
has `â€–E âˆ’ E_trueâ€– = 0` in the function-space norm where `E_true` is the oracle expert.
Miscalibration (`Î´ >> 0`) signals that the expert's internal model of the swarm diverges
from reality â€” a lesson candidate or belief challenge.

**Key property**: Calibration is a *convergence accelerant*. A well-calibrated expert
pool converges to `s*` faster (fewer wasted sessions) because predictions guide
resource allocation.

---

## 6. Dispatch as Bipartite Matching

Expert assignment solves a **maximum-weight bipartite matching** problem:

```
maximize   Î£_{e,d} w(e,d) Â· x(e,d)

subject to:
  Î£_d x(e,d) â‰¤ 1         âˆ€e   (one lane per expert per session)
  Î£_e x(e,d) â‰¤ cap(d)    âˆ€d   (domain capacity limit)
  x(e,d) âˆˆ {0,1}
```

where:
- `w(e,d)` = expected swarm-facing ROI of expert `e` on domain `d`
  (estimated from historical artifact quality Ã— frontier urgency)
- `cap(d)` = maximum concurrent experts on domain `d`

`tools/dispatch_optimizer.py` (F-ECO4) implements this. The weight function
`w(e,d)` encodes several factors:
- Expert personality fit for domain type
- Domain urgency (DUE / URGENT thresholds from maintenance.py)
- Coverage gap (domains with zero active lanes get bonus weight)
- Swarm-facing ROI estimate (meta-domains weighted higher)

**Extension to bundles**: When expert pairs are required (e.g., Idea Investigator +
Skeptic), the matching becomes a **hypergraph matching** over expert tuples rather than
individual experts. The constraint becomes:

```
âˆ€ bundle B âˆˆ required_bundles: Î£_{(e,d) âˆˆ B} x(e,d) = 1   (the whole bundle or none)
```

---

## 7. The Colony Structure as a Presheaf

The domain-colony structure (F-STRUCT1) is a **presheaf** over the domain category `ğ’Ÿ`:

```
F : ğ’Ÿ^op â†’ Set

F(d) = local swarm state for domain d
       (lessons, frontiers, colony beliefs, lanes)

F(d â†’ d') = restriction map: cross-domain isomorphism extraction
            ("what from domain d transfers to domain d'?")
```

**Global sections** `Î“(F)` are the elements consistent across all domains â€” these are the
globally shared beliefs, principles, and lessons in `memory/` and `beliefs/`.

The **sheaf condition** would require that locally consistent knowledge glues to globally
consistent knowledge. In practice the swarm does not enforce the full sheaf condition â€”
contradictions between domain-local findings and global beliefs generate `CHALLENGES.md`
entries. Processing challenges is the sheaf-repair operation.

**HÂ¹ (first cohomology) interpretation**: When local domain knowledge *cannot* be
consistently glued into global knowledge â€” when challenges remain open and no consensus
emerges â€” this is a non-zero first cohomology class. The swarm expert for the swarm
explicitly hunts these obstructions. A zero `HÂ¹` would mean perfect knowledge integration
(unreachable, but approached).

---

## 8. Self-Similarity and Fractal Structure

The swarm expert for the swarm makes the system **self-similar**:

```
Swarm â‰… Expert_Pool(Swarm)
```

The swarm at scale is isomorphic to an expert pool *whose domain is the swarm itself*.
This is the same structure at every level:

- A single expert session: orient â†’ act â†’ compress â†’ handoff
- A colony: orient â†’ act (domain experiment) â†’ compress (lesson) â†’ handoff (LANES update)
- The global swarm: orient â†’ act (session) â†’ compress (compaction) â†’ handoff (NEXT.md)

The swarm expert for the swarm is the **self-similar fixed point** of this recursive
structure: applying the swarm pattern to itself produces the same pattern.

In fractal terms, the swarm is an **iterated function system** where the attractor is
`s*` and the swarm expert for the swarm is the contraction mapping that drives convergence.

---

## 9. Information-Theoretic View

Each expert session is an **information channel**:

```
I(S_after; S_before, E) = mutual information gained by running expert E
```

The swarm's efficiency is:

```
Î· = I(S_after; S_before, E) / C(E)
```

where `C(E)` is the token cost of running expert `E`.

The swarm expert for the swarm maximizes **meta-efficiency**:

```
Î·_meta = Î£_E [Î·(E) after meta-expert] / C(E_meta)
```

It improves the compression algorithm itself â€” it is not just compressing knowledge,
but compressing how knowledge is compressed. This is the compactification principle:
the context window is the forcing function, and the swarm expert makes compression
better under that constraint.

---

## 10. Summary Table

| Structure | Mathematical Object | Swarm Instantiation |
|---|---|---|
| Swarm state | Complete lattice `(S, âŠ‘)` | Lessons Ã— Principles Ã— Frontiers Ã— ... |
| Expert | Typed function `E: DÃ—S â†’ AÃ—Î”S` | Personality + lane + artifact |
| Swarm operator | Monotone function `S_op: S â†’ S` | Join of concurrent expert Î”S |
| Convergence | Knaster-Tarski LFP | s* = indefinite compounding |
| Meta-expert | Higher-order operator `Åœ: (Sâ†’S)â†’(Sâ†’S)` | Protocol / dispatch improvements |
| Meta-convergence | Y-combinator `Y(Åœ) = Åœ(Y(Åœ))` | Self-stabilizing swarm protocol |
| Calibration | Operator norm `â€–E âˆ’ E_trueâ€–` | Expect-act-diff distribution |
| Dispatch | Max-weight bipartite matching | dispatch_optimizer.py (F-ECO4) |
| Colony structure | Presheaf `F: ğ’Ÿ^op â†’ Set` | domain/ directories + COLONY.md |
| Knowledge integration | Global sections `Î“(F)` | beliefs/ + memory/ |
| Unresolved contradictions | HÂ¹ cohomology | CHALLENGES.md open entries |
| Self-similarity | IFS attractor | Swarm pattern at every scale |

---

## Open Questions (â†’ F-META5)

1. **Convergence rate**: How fast does `S_op^n(âŠ¥)` approach `s*`? What is the contraction
   constant, and does duplication overhead dominate at high concurrency?

2. **HÂ¹ tractability**: Can `CHALLENGES.md` entries be automatically classified by
   cohomological type (local vs global contradiction)?

3. **Y-combinator stability**: Does `lfp(Åœ)` exist and is it unique? Can a session
   destabilize the meta-level by a bad protocol change?

4. **Presheaf enforcement**: Should the swarm enforce the full sheaf condition (auto-reject
   globally inconsistent domain findings)? Or is open HÂ¹ a useful diversity signal?

5. **Calibration-dispatch coupling**: Can `cal(E)` be used directly in `w(e,d)` to weight
   well-calibrated experts higher? Expected outcome: faster convergence with same token budget.

---

*See also*: `docs/EXPERT-SWARM-STRUCTURE.md` (operational contract),
`beliefs/CORE.md` (principles), `tools/dispatch_optimizer.py` (F-ECO4 dispatch math).
