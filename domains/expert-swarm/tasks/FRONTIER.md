# Expert Swarm Domain — Frontier Questions
Domain agent: write here for expert-swarm-specific questions; cross-domain findings go to tasks/FRONTIER.md
Updated: 2026-03-01 S353 | Active: 9

## Active

- **F-EXP1**: Does dispatch_optimizer.py score-ranked selection increase domain experiment throughput vs random dispatch? Baseline: 2% session throughput (S301). S305 PARTIAL: `tools/dispatch_tracker.py` built — sessions claim/release frontiers via shared `workspace/DISPATCH-LOG.md`; `check_dispatch_log()` in maintenance.py flags stale in-progress entries. Design: instrument 10 sessions with claim/release; compare throughput (dispatch_optimizer top-5 vs random selection control). Instrument: `tools/dispatch_tracker.py`. Cross-link: economy/F-ECO4.
  - **S353 analysis**: F-ECO4 showed 45x throughput improvement (2%→90%), but this is CONFOUNDED with the one-shot DOMEX norm (S327, L-444) which drove merge rate from 8.3%→100%. Pre/post S344 (outcome feedback): merge rate 100% (S327-S343) → 88.6% (S344+) = no improvement. Scoring drives DOMAIN SELECTION (WHERE), not COMPLETION (WHETHER). The throughput question is answered: one-shot norm is the mechanism, scoring is the allocator. F-EXP1 near-resolution: reframe as "does scoring improve allocation quality?" — test via L/lane variation across scored vs random domains.

- **F-EXP2**: Does companion expert bundling (idea-investigator + skeptic, per EXPERT-SWARM-STRUCTURE.md) reduce per-finding coordination overhead vs solo dispatch? Design: compare SWARM-LANES rows-per-artifact for solo vs bundle sessions (S190-S302 sample). Instrument: SWARM-LANES.md parse. Cross-link: operations-research.

- **F-EXP3**: What % of expert capacity (personality files × domain lanes) is utilized per session? Baseline: 44 personalities × 37 domains = ~1,628 capacity-slots; active DOMEX lanes ~75; utilization ~4.6%. Design: measure active dispatch coverage per session for 10 sessions. Instrument: maintenance.py domain-coverage check. (S306)

- **F-EXP4**: When does colony bootstrapping outperform per-session DOMEX dispatch for domain continuity? Design: compare meta/brain colonies (new COLONY.md pattern) vs equivalent non-colony domains on: time-to-artifact, frontier closure rate, lesson production per session. Instrument: `tools/swarm_colony.py status`. Cross-link: control-theory. (S306)

- **F-EXP6**: How do swarm colonies interact peer-to-peer? S304 baseline: 81.1% passive (INDEX.md), 0% active (SIGNALS.md). S305 update: active signal rate 0%→5.4% (2/37 colonies have SIGNALS.md, 6 edges). S307 update: 2 new SIGNALS.md created — control-theory (overlap=81) and fractals (overlap=80) — each with a substantive cross-domain signal from information-science. Active signal rate now 4/37 = 10.8%, crossing 10% target. Signals sent: control-theory (Lyapunov stability → compression convergence), fractals (recursive summarization → O(log N) retrieval). Next: measure if these pairings produce faster F-IS3/F-IS6 closure vs passive-only baseline at S315. Instrument: `tools/colony_interact.py map/suggest/signal`. Cross-link: protocol-engineering, distributed-systems.

- **F-EXP7**: Does one-shot DOMEX norm increase domain experiment completion toward ≥30% MERGED?
  Status: CONFIRMED S341 — Pre-norm (n=36): 8.3% MERGED. Post-norm (n≈20, S327-S342): 100% MERGED, 0% ABANDONED (12x improvement). 12+ domains confirmed (meta 5, LNG 5, NK 3, + 8 single-domain lanes). One-shot = only proven completion pattern. Domain-independent.
  Artifact: experiments/expert-swarm/f-exp7-oneshot-domex-s329.json, f-exp7-oneshot-domex-s341.json | L-444
  Open: (1) continue monitoring as n→50; (2) test multi-session DOMEX with explicit continuation protocol; (3) correlate domain heat with MERGED quality (L per lane).

- **F-EXP9**: Does maxing swarm spread maximize expert council ability? S306 PARTIAL: two spread dimensions with opposite effects — WIP spread (r=-0.835, HURTS) vs synthesis spread (+4.5x yield, HELPS). Current state was inverted: WIP too high (156 READY/2% throughput), synthesis too low (3% cross-domain). S307 update: WIP spread resolved — 156→32 READY (80% reduction). Synthesis spread unchanged at 3% (10/347 cross-domain, ISO density 30%). Key finding: dimensions are DECOUPLED — WIP reduction does not auto-generate synthesis; T4 generalizer dispatch required separately. Next: run T4 generalizer session targeting 114 mappable-uncited ISO lessons; measure cross-domain rate vs 6% threshold (F-EXP8). Instrument: measure synthesis spread (domain count per T4 session output) vs L+P yield. Artifact: experiments/expert-swarm/f-exp9-spread-ability-s306.json. L-387, L-407.

- **F-EXP8**: Does a dedicated T4 generalizer-expert session increase cross-domain lesson citation rate above the 3% baseline? Baseline: 3% cross-domain (9/326 lessons, S306); 5x compression gap. Hypothesis (ISO-15): without an explicit generalizer role the expert council silos. Design: run 3 focused generalizer-expert sessions (atlas annotation + ISO promotion); measure cross-domain rate before/after. Instrument: `python3 tools/generalizer_expert.py` (reports cross-domain % and ISO density). Target: >6% (2x baseline). Artifact: ISO-15 added to atlas (S306), L-379. Cross-link: F-EXP3, F-EXP7.

- **F-EXP10**: Does wiring outcome feedback into dispatch_optimizer.py scoring improve dispatch quality? S343 council (5/5 convergence): dispatch scores are structural (ISO count, frontier count) not empirical (actual lesson yield). Design: after each DOMEX MERGED, log lessons_produced, cross_citations_added, frontiers_advanced, proxy_k_spent. Add empirical_yield factor to scoring. Compare dispatch quality (Sharpe of dispatched lessons) before/after over 20 sessions. Baseline: current scoring is committee-priced (no market feedback). Instrument: dispatch_optimizer.py + outcome log. Cross-link: F-ECO4, F-EXP1. Council: workspace/COUNCIL-EXPERT-SWARM-S343.md P1. L-501.
  - **S353 BREAKTHROUGH**: Outcome feedback was dormant for 8 sessions (S344-S352) — dispatcher only read SWARM-LANES.md (44 lanes), missing 265 archived lanes (86% of history). Fix: read both files. Result: 1→8 domains with outcome labels. 2 PROVEN (meta 19/23, nk-complexity 13/17), 3 STRUGGLING (governance 1/3, economy 1/4, brain 5/11). Score rankings shifted (brain -6.1). L-572. Artifact: `experiments/expert-swarm/f-exp10-outcome-quality-s353.json`. F-EXP10 PARTIAL→ADVANCED.
  - **S363 YIELD MEASUREMENT**: 157 MERGED DOMEX lanes cross-tabulated by outcome label. **NON-MONOTONIC**: MIXED 1.42 L/lane > PROVEN 1.21 > UNLABELED 1.05 > STRUGGLING 0.88. PROVEN shows diminishing returns (first-half 1.31→second-half 1.12, −15%). Fix: OUTCOME_BONUS reduced 1.5→0.5 for PROVEN, added MIXED_BONUS +2.0. MIXED domains now rank higher. L-654. Artifact: `experiments/expert-swarm/f-exp10-yield-by-outcome-s363.json`. F-EXP10 → NEAR-RESOLVED. Next: re-measure after 20 sessions with new scoring — does MIXED dispatch improve aggregate L/session?

## Resolved
| ID | Answer | Session | Date |
|----|--------|---------|------|
| F-EXP5 | YES — annotation pass raised cite rate 3.4%→8.5% (2.5x), gap 13x→5x. ISO-14 added to atlas. 18 lessons annotated. | S303 | 2026-02-28 |
