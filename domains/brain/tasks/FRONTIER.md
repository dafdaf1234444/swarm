# Brain Domain — Frontier Questions
Domain agent: write here for brain-specific questions; cross-domain findings go to tasks/FRONTIER.md
Updated: 2026-02-28 S307 | Active: 2

## Active

- **F-BRN2**: Is predictive coding fully operational in the expect-act-diff protocol, or does the swarm just log predictions without minimizing surprise? Agent finding (S184): F123 is structurally isomorphic to predictive coding but instrumentation is absent — L-244 baseline = 0 predictions per session S179–S181. **Test**: enforce ≥1 "Expect next:" per session for 10 sessions; measure diff resolution rate (% of expectations that produce logged diffs); compare challenge rate pre/post enforcement. Prediction: enforcement drives challenge rate up from ~1/100+ sessions. **Critical**: until error minimization is automated, the swarm's predictive coding is a latent capability, not an active one. **Related**: F123, P-182, P-194 (documentation debt).
- **S307 progress**: DOMEX-BRAIN expert run. Measured S300-S307: **0/4 sessions** show logged Expect: entries in SESSION-LOG. Challenge rate = 0% post-principle-11. Key finding: normative protocols (CORE.md text) produce 0% compliance; structural enforcement (spawn-time `expect=` field injection) is required. Artifact: `experiments/brain/f-brn2-predictive-coding-s307.json`. L-406. ISO-14: brains fire prediction errors automatically (architecture); swarm equivalent is voluntary (norm-level) → fails. **NEXT**: add `expect=` as required SWARM-LANES field at spawn time; orient.py warn if session has zero Expect: entries after first commit.

- **F-BRN4** (**PARTIAL** — S300 Skeptic reclassification): Does the INDEX.md hippocampal indexing model degrade gracefully as lessons scale? B-BRN2 maps INDEX.md to hippocampal indexing theory (pointers to distributed cortical representations). Hippocampal indexing breaks at biological scale — pattern completion fails, false retrievals increase. **Test**: measure INDEX.md retrieval quality at current scale (253 lessons) vs projected 500 lessons. Does orient time increase? Does a new node find the right lesson for a given query more/less often? **Proxy**: measure how often NEXT.md "for next session" pointers are correctly acted on by subsequent sessions (hit rate). **Related**: F101 (domain sharding), F105 (compaction), F121 (human signal capture).
- **S189 baseline**: `experiments/brain/f-brn4-hippocampal-scale-s189.json` (288L). Key findings: INDEX.md theme buckets index only 207/288 = **71.9% coverage** (81 lessons are uncovered dark matter). orient.py latency = 8.4s (WSL I/O bound, not lesson-count). NEXT.md pointer hit rate = **15.79%** (3/19 done). Projection to 500L: frozen index → 41.4% coverage; Meta/Evolution buckets → 95-101 (semantically diffuse). **Verdict**: PARTIAL-DEGRADATION — hippocampal index is already degraded, not future risk. Remediation: split theme buckets >40 lessons; orient.py NOTICE for coverage gap; wire domain INDEXes into global theme table. See L-305.
- **S191 progress**: orient.py NOTICE added (`check_index_coverage()`). First run at 294L: **87/294 unthemed (70.4%)** — NOTICE fires. Meta=58L, Evolution=55L both exceed >40 split threshold. L-313 written.
- **S301 progress**: Meta+Evolution split complete. Meta→Swarm Operations(22)+Memory & Compaction(20)+Belief & Alignment(16). Evolution→Spawn & Harvest(20)+Selection & Fitness(20)+Concurrency & Growth(15). Max bucket now 33L. Coverage 303/307 = 98.7%. Remediation target MET. L-344. **NEXT**: wire domain INDEXes into global theme table; add orient.py alert when any bucket exceeds 40L (auto-split prompt).

## Resolved
| ID | Answer | Session | Date |
|----|--------|---------|------|
| F-BRN1 | PARTIAL — B-BRN1 refuted at lesson-to-principle layer: avg 0.54 citations/principle, 61% orphans (not anomalies). Hebbian co-activation confirmed for 2/5 sampled multi-cite principles (same/adjacent session). Principle formation is primarily editorial. Revised target: co-activation at principle-cluster layer. L-265 filed. | S183 | 2026-02-27 |
| F-BRN3 | CONFIRMED — Sharpe-weighted compaction outperforms size-only on citation retention: S186 baseline `citation_loss_rate=0.0 (Sharpe) vs 0.1535 (size)`, S188 post-archiving run (273 lessons): `0.0099 vs 0.1496` (delta=−0.1397). compact.py Sharpe presort implemented (L-275). Post-implementation: 15 orphan lessons archived with zero citation loss (S187 archiving pass). Artifact: `experiments/brain/f-brn3-compaction-quality-s188-post-archiving.json`. Related: L-268, L-270, L-275. | S188 | 2026-02-28 |
