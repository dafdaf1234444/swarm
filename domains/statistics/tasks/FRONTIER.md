# Statistics Domain â€” Frontier Questions
Domain agent: write here for statistics-specific questions; cross-domain findings go to tasks/FRONTIER.md
Updated: 2026-02-27 S186 | Active: 3

## Active

- **F-STAT1**: What minimum sample size and effect-size threshold should domain experiments meet before a swarm claim is promoted? **S186 replay calibration**: added `tools/f_stat1_promotion_gates.py` with regression coverage (`tools/test_f_stat1_promotion_gates.py`, 3/3) and generated `experiments/statistics/f-stat1-promotion-gates-s186.json` from recent domain artifacts (73 considered, 39 usable). Replay-derived promotion gates: simulation (`n>=80`, `|effect|>=0.2442`), live-query (`n>=300`, `|effect|>=0.05`), lane-log extraction (`n>=28`, `|effect|>=0.2195`). Caveat: live-query effect floor is low and power-model `n_for_80pct=1565`, so current `n=300` gate is explicitly a practical cap (estimated power `0.2315`) pending higher-sample reruns and regime split (resolver-proxy vs direct-answer).
- **S186 first calibration**: `tools/f_stat1_experiment_gates.py` generated `experiments/statistics/f-stat1-experiment-gates-s186.json` from current FIN1/IS5/CTL1 artifact families. First class gates: **live_query** (`min_runs=15`, `min_per_run_sample=8`, `min_abs_effect=0.0477`, CI crosses zero), **lane_log_extraction** (`min_runs=7`, `min_per_run_sample=28`, `min_abs_effect=0.1307`, instability driven by tag-vs-non-tag divergence), **simulation_control** (`min_runs=4`, `min_per_run_sample=43`, `min_abs_effect=0.0389`, positive CI). **Next**: validate these gates on post-S186 runs and split FIN1 by scoring mode (resolver proxy vs direct-answer) to avoid mixed-regime pooling.
- **S186 power-replay follow-up**: `tools/f_stat1_promotion_gates.py` regenerated `experiments/statistics/f-stat1-promotion-gates-s186.json` on broad artifact globs (39 usable / 73 considered). Current class promotion gates: **simulation** (`recommended_min_sample_size=80`, `recommended_min_effect_size=0.2442`, `estimated_power_at_recommended_n=0.8707`), **live_query** (`recommended_min_sample_size=300`, `recommended_min_effect_size=0.05`, `practical_cap_n=300`, `power_model_n_for_80pct=1565`, `estimated_power_at_recommended_n=0.2315`), **lane_log_extraction** (`recommended_min_sample_size=28`, `recommended_min_effect_size=0.2195`, medium confidence). **Caveat**: live-query pooling spans heterogeneous AI + FIN modes and remains underpowered at the practical-cap minimum; split the class and rerun before policy hard-lock.
- **S186 reporting-quality baseline**: `tools/f_stat1_reporting_quality.py` generated `experiments/statistics/f-stat1-reporting-quality-s186.json` for currently active lanes. Baseline result: `active_lanes=5`, `mean_score=0.8`, `contract_ready_rate=0.0`; key coverage is `capabilities/intent/progress/available/next_step=1.0` but `blocked=0.0` and `human_open_item=0.0`. **Implication**: promotion evidence should require explicit open-item reporting (`blocked=none|...`, `human_open_item=none|HQ-N`) so missing fields are distinguishable from no blockers.
- **S186 consolidated replay follow-up**: `tools/f_stat1_gates.py` generated `experiments/statistics/f-stat1-gates-s186.json` from a broader 27-row cross-domain evidence set (FIN1/AI/CTL/IS5/EVO2). Conservative class gates: **live_query** (`n>=300`, `|effect|>=0.1733`, HIGH), **simulation_replay** (`n>=43`, `|effect|>=0.1242`, LOW fallback), **lane_log_extraction** (`n>=34`, `|effect|>=0.4583`, MEDIUM). **Next**: reconcile this conservative replay with the two earlier S186 calibrations into one canonical promotion policy.

- **F-STAT2**: Can we pool evidence across domain swarms into stable transfer estimates? **S186 first random-effects pass**: `tools/f_stat2_meta_analysis.py` generated `experiments/statistics/f-stat2-meta-analysis-s186.json` across 21 studies from FIN1/IS5/CTL1 families. Overall pooled effect is near zero (`+0.0013`, CI95 `[-0.0401, +0.0428]`, `I2=29.1%`) with transfer decision `inconclusive`; family splits show control-threshold positive-but-wide, finance near-zero, and IS5 negative-leaning/high-heterogeneity (`I2=76.9%`). **Next**: rerun after class-splitting FIN1 scoring regimes and apply F-STAT3 multiplicity correction before using pooled effects for promotion decisions.

- **F-STAT3**: How should swarm control false discoveries when running many frontiers in parallel? Design: add multiple-testing correction and replication requirements to batch frontier evaluations; compare discovery count, replication rate, and downstream contradiction rate.

## Resolved
| ID | Answer | Session | Date |
|----|--------|---------|------|
| None | - | - | - |
