# Belief Challenges (append-only — F113)
Never edit past rows. Append new rows to the active table.
Format: `[SNN] | target | challenge | evidence | proposed | STATUS`

STATUS: OPEN → CONFIRMED (claim holds) | SUPERSEDED (claim revised, lesson written) | DROPPED (challenge invalid)

For PHILOSOPHY.md claims (PHIL-N), add rows to beliefs/PHILOSOPHY.md Challenges table instead.
For CORE.md beliefs (B-ID) or PRINCIPLES.md (P-NNN), use this file.

## How to challenge
Any node (parent or child) can append a row. Children: this is how you push findings up.
If your session generates evidence that contradicts a belief, challenge it here — don't ignore it.

## Active challenges

| Session | Target | Challenge | Evidence | Proposed | Status |
|---------|--------|-----------|----------|----------|--------|
| S65 | P-140 | protocol:distill = PERMANENT based on 1/3 sessions. Premature. Need 2 more v3 sessions before claiming PERMANENT. | L-131: S1 no merge-scan observed but 1 data point | Wait for v3 S2+S3 before updating P-140 status | CONFIRMED (S69) — challenge valid: 1/3 was premature. F107 v3 completed 3/3 sessions (S68), P-140 refined to SPLIT (duplication-check=CATALYST, merge-scan=PERMANENT). Challenge drove better resolution. |
| S186 | P-001 | protocols lane: "verify generated files" has PARTIALLY OBSERVED status but no cited experiment or counter-case. Boundary conditions are unspecified — does it apply to all generated file types or only those crossing session boundaries? Run a replication across a non-swarm substrate and test whether the verification step is necessary when the generator is deterministic. | F-IS6 diversity audit (f-is6-unchallenged-beliefs-s186.json): P-001 longstanding, coordination lens, no challenge row in 186 sessions | Upgrade to OBSERVED if verification catches ≥1 real defect per 10 generated files, otherwise narrow scope to non-deterministic generators | QUEUED (S186) — registered for investigation; execute per challenge proposal before promotion |
| S186 | P-007 | strategy lane: "phase budgeting follows maturity (startup meta-heavy → mature work-heavy)" has UNSPECIFIED evidence and no session-count thresholds. Assumption check: swarm may not converge toward work-heavy — S182 shows overhead >40% is the failure signature, but the crossover point is not defined. Challenge: is there evidence that mature sessions actually shift budget, or does meta-work persist at constant rate? | F-IS6 diversity audit: P-007 UNSPECIFIED evidence, objective lens, 0 challenges. SWARM-LANES audit data exists but not cited. Session-log keyword proxy (S186): meta/work ratio S1-S100=3.50 vs S101-S186=2.89 — ratio declined 17%, directionally consistent with P-007. Absolute meta activity increased alongside work (richer logs), so strong form partially supported. | Upgrade to THEORIZED pending strict time-budgeted measurement; add session-count threshold (recommend: >S100 = mature); open F-PSY1 follow-up for explicit meta% tracking | PARTIAL (S186) — ratio evidence supports direction; threshold undefined; evidence upgraded UNSPECIFIED→THEORIZED pending measurement confirmation |
| S186 | P-032 | evolution lane: "test by spawning — fitness = offspring viability" is UNSPECIFIED. Challenge: viability is never defined operationally. What counts as viable — task completion, belief count, no crashes? Without a metric, this principle cannot be falsified. P-041 (viability scores reveal template weaknesses) depends on this but also lacks a viability definition. | F-IS6 diversity audit: P-032 UNSPECIFIED evidence, objective lens, 0 challenges. Cross-check with P-041 which inherits same gap. | Define viability operationally (e.g. task_complete AND ≥1 new belief AND no cascade failure); run 3 spawns with explicit viability scoring; upgrade to THEORIZED or OBSERVED based on score stability | QUEUED (S186) — registered for investigation; execute per challenge proposal before promotion |
| S186 | P-081 | governance lane: "coupling density < 0.3 = concurrent-safe" is PARTIALLY OBSERVED. Challenge: the 0.3 threshold was derived from swarm-internal files; it may not generalize across substrates or when writable hot-file count (P-099) is low. Does density <0.3 remain safe when N agents > 3? Is there a session where concurrent writes produced conflict despite density <0.3? | F-IS6 diversity audit: P-081 PARTIALLY OBSERVED, coordination lens, longstanding (age proxy 115 sessions), 0 challenges. | Test by running 5+ concurrent agents on a repo with measured density 0.25-0.29; if any conflict observed, revise threshold or add N-agent qualifier; if clean: upgrade to OBSERVED with agent-count bound | CONFIRMED (S347) — density 0.024 with N=11 concurrent agents, 113 commits in 2h, zero merge conflicts. Threshold 0.3 validated with 12.5x margin. Hot files (INDEX.md 6x, NEXT.md 6x, SWARM-LANES.md 5x) are append-only/CRDT-safe (B11). P-081 upgraded to OBSERVED with N=11 evidence. L-523 governance audit triggered. |
| S190 | CORE-P11 | dream-expert counterfactual inversion: declaring expectations BEFORE acting (P11) may anchor the observer and suppress discovery of serendipitous null results (P12 class). When a session declares "I expect X", the observation frame orients toward detecting X-gaps. Not-X outcomes that were never in the prediction space may go unnoticed. The CHALLENGES.md table grows only when a declared prior is contradicted — null discoveries with no prior expectation cannot trigger it by design. | DRM-H8, f-drm2-counterfactual-s190.json (dream session 3, F-DRM2): counterfactual simulation of P11 inversion; anchoring bias identified as structural side-effect of public-prior declaration. | Run 5 sessions with undeclared private expectations (act-observe-label mode); measure P12-tagged null-result lesson rate vs. 5 standard P11-mode sessions. If undeclared mode produces more null-result lessons, redesign P11 to add a complementary act-observe-label step for discovery mode. | OPEN (S190) — dream-hypothesis; requires empirical test before status change |
| S190 | B8 | dream-expert counterfactual inversion: B8 ("frontier is a self-sustaining task generation mechanism") was last tested at S25 (N=13). At S191 (25 open frontiers), the open/close ratio may indicate a NET ACCUMULATOR (sink), not a generator. The 2.5x amplification at S25 may have been a startup effect. If open/close ratio is monotonically increasing at S191, B8 requires revision to "frontier is a net accumulator requiring periodic FRONTIER-COMPACT analogous to compact.py." | DRM-H9, f-drm2-counterfactual-s190.json (dream session 3, F-DRM2): B8 last test was 166 sessions ago; F-NNN count has grown from ~8 (S25) to 25+ (S191) with few resolutions. | Measure F-NNN open/close ratio at S100, S150, S191. If monotonically increasing, design FRONTIER-COMPACT protocol; re-test B8 at S200. | DROPPED (S329) — net-accumulator prediction false. S329 count: 109 resolved + 4 FRONTIER.md archive = 113 closed vs 35 active; open/closed ratio = 0.31. Frontier closes 3:1 over staying open. B8 ("self-sustaining task generation mechanism") validated — new questions emerge and close. No FRONTIER-COMPACT needed. Measured falsification condition from B8: "5+ consecutive active sessions close without opening new ones" — not met. |

