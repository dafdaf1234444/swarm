{
  "frontier": "F95",
  "session": "S359",
  "date": "2026-03-01",
  "domain": "distributed-systems",
  "hypothesis": "B14 claims 98% of distributed bugs reproduce with ≤3 nodes and 74% are deterministic. Analytical classification of 5 Jepsen-discovered bugs should confirm or refute both claims independently.",
  "methodology": "Web research on actual bug reports + Jepsen analyses + analytical classification of 5 bugs (etcd #11456, CockroachDB timestamp cache #9083, Redis-Raft #14/#17/#19). Each classified on: minimum node count, 3-node feasibility, determinism, reproduction complexity, bug type.",
  "sources": [
    "github.com/etcd-io/etcd/issues/11456",
    "github.com/etcd-io/etcd/issues/11457",
    "jepsen.io/analyses/etcd-3.4.3",
    "jepsen.io/analyses/cockroachdb-beta-20160829",
    "github.com/cockroachdb/cockroach/issues/9083",
    "jepsen.io/analyses/redis-raft-1b3fbf6",
    "github.com/RedisLabs/redisraft/issues/14",
    "github.com/RedisLabs/redisraft/issues/17",
    "github.com/RedisLabs/redisraft/issues/19",
    "Yuan et al. OSDI 2014 (198 bugs, 5 systems)",
    "Demirbas critique (2015) — 92% EH figure inflation",
    "Liu et al. HotOS 2019 (112 Azure incidents)",
    "McCaffrey ACM Queue 2016 (Jepsen-Yuan bridge)"
  ],
  "bug_classifications": [
    {
      "id": "etcd-11456",
      "system": "etcd 3.4.3",
      "type": "logic (client library)",
      "description": "Lock returns without checking lease validity. Lock waits for previous holder to release, but does not re-check if waiting client's own lease is still alive. Lease can expire during wait; client falsely believes it holds lock.",
      "root_cause": "clientv3/concurrency/key.go line 57 — checks if previous holder's key is gone but never validates requesting client's lease status",
      "min_nodes": 1,
      "realistic_min_nodes": 3,
      "three_node_feasible": true,
      "deterministic": false,
      "determinism_detail": "Timing-dependent but wide race window (entire lease TTL period). Jepsen: 18% loss rate under standard nemesis. Highly reproducible in practice.",
      "complexity": "low",
      "infrastructure": "Docker + concurrent clients + process pauses (SIGSTOP). Short lease TTL (2s).",
      "jepsen_config": "5 nodes, process pauses every 5s, 2s lease TTL",
      "b14_node": "SUPPORTS",
      "b14_det": "PARTIAL (timing-dependent but easy)"
    },
    {
      "id": "cockroachdb-9083",
      "system": "CockroachDB beta-20160829",
      "type": "logic (timestamp cache)",
      "description": "Timestamp cache stores (span, timestamp) but ignores transaction ID. Two transactions T1/T2 with identical HLC timestamp on same key are treated as equivalent — T2 steals T1's cache entry. Causes serializability violation.",
      "root_cause": "TimestampCache.Add() compares by (timestamp, key_span) only, not txn_id. HLC clock skew between nodes produces duplicate timestamps more often than nanosecond precision suggests.",
      "min_nodes": 3,
      "realistic_min_nodes": 5,
      "three_node_feasible": "marginal",
      "three_node_note": "At replication factor 3 (CockroachDB default), timestamp caches synchronize after every write, suppressing the bug. Reliable reproduction needs 5 nodes where ranges split across different caches.",
      "deterministic": false,
      "determinism_detail": "Minutes to hours to reproduce at 20 txns/sec. Requires clock skew between nodes to produce identical timestamps. Probabilistic.",
      "complexity": "high",
      "infrastructure": "Docker + clock skew injection (NTP offset) + sustained concurrent load (~20 txns/sec)",
      "jepsen_config": "5 nodes, clock skew nemesis, monotonic test workload",
      "b14_node": "MARGINAL (3 nodes possible but suppressed)",
      "b14_det": "CHALLENGES (narrow window, hours to reproduce)"
    },
    {
      "id": "redis-raft-14",
      "system": "Redis-Raft 1b3fbf6",
      "type": "logic (state machine re-entrancy)",
      "description": "Total data loss on EVERY failover. Missing re-entrancy check in Raft command pipeline. Followers intercept operations and re-raftize them instead of applying to FSM. On leader election, new leader has no applied state.",
      "root_cause": "Commands cycle through Raft log without reaching state machine. Same re-entrancy bug as issue #13.",
      "min_nodes": 3,
      "three_node_feasible": true,
      "deterministic": true,
      "determinism_detail": "100% reproducible on every leader election. Not a race condition — systematic logic error.",
      "complexity": "low",
      "infrastructure": "Docker Compose with 3 Redis instances. Kill leader (kill -9), read data — all gone.",
      "reproduction": "Write keys → kill leader → read keys from new leader → empty",
      "b14_node": "SUPPORTS",
      "b14_det": "STRONGLY SUPPORTS (deterministic)"
    },
    {
      "id": "redis-raft-17",
      "system": "Redis-Raft d589127",
      "type": "protocol (membership change safety)",
      "description": "Isolated leader unilaterally removes all other nodes from membership, declares itself sole member of 1-node cluster, continues accepting writes. On partition heal → split-brain data loss.",
      "root_cause": "Raft library (RedisLabs/raft) excluded RAFT_LOGTYPE_REMOVE_NODE from voting configuration change types. Node-removal commits bypass majority consensus check.",
      "min_nodes": 3,
      "three_node_feasible": true,
      "deterministic": true,
      "determinism_detail": "Deterministic given partition + RAFT.NODE REMOVE command. Logic error — not timing-dependent.",
      "complexity": "medium",
      "infrastructure": "Docker + iptables partition injection. Partition leader → issue RAFT.NODE REMOVE → write to both sides → heal → verify data loss.",
      "b14_node": "SUPPORTS",
      "b14_det": "SUPPORTS (deterministic given sequence)"
    },
    {
      "id": "redis-raft-19",
      "system": "Redis-Raft d589127",
      "type": "protocol (leader initialization)",
      "description": "Stale reads in normal operation with ZERO faults. Missing no-op log entry on leader election — new leader doesn't know which entries are committed. Reads return stale state.",
      "root_cause": "Raft protocol requires new leader to issue no-op entry to establish commit index. Redis-Raft's bundled Raft library omitted this. Same root cause as #18.",
      "min_nodes": 3,
      "three_node_feasible": true,
      "deterministic": true,
      "determinism_detail": "100% reproducible with zero fault injection. Triggers on every leader election. Jepsen reproduced with --nemesis none.",
      "complexity": "low",
      "infrastructure": "Docker Compose with 3 Redis instances only. No fault injection needed.",
      "reproduction": "Write data → trigger leader election → read data → stale result",
      "jepsen_command": "lein run test-all --raft-version d589127 -w append --time-limit 120 --nemesis none",
      "b14_node": "SUPPORTS",
      "b14_det": "STRONGLY SUPPORTS (deterministic, no faults needed)"
    }
  ],
  "results": {
    "node_count_claim_98pct": {
      "verdict": "SUPPORTED",
      "strict_rate": "4/5 (80%)",
      "generous_rate": "5/5 (100%)",
      "detail": "CockroachDB marginal at 3 nodes (cache sync suppresses bug). All others clearly ≤3 nodes. n=5 too small to falsify 98% (CI includes 98%)."
    },
    "determinism_claim_74pct": {
      "verdict": "PARTIALLY SUPPORTED",
      "strict_deterministic": "3/5 (60%)",
      "including_easy_timing": "4/5 (80%)",
      "detail": "Redis-Raft #14/#17/#19 deterministic. etcd timing-dependent but wide window. CockroachDB genuinely hard. 60-80% range brackets the 74% claim."
    },
    "structural_pattern": {
      "finding": "Bug architecture layer predicts determinism",
      "gradient": "state-machine (100% det) > protocol-spec (det given sequence) > client-server race (wide timing) > distributed-clock (narrow timing)",
      "iso": "ISO-5 (feedback): lower abstraction layers = tighter feedback loops = more deterministic manifestation"
    },
    "p095_validated": "Confirmed: determinism and node-count are independent axes. CockroachDB = low-det + 3-node feasible. Redis-Raft #19 = high-det + needs exactly 3 nodes.",
    "yuan_critique_applied": {
      "demirbas": "5/5 bugs involve 'error handling' broadly, but only 2/5 (etcd #11456, Redis-Raft #14) are classic EH anti-patterns. 3/5 are protocol design bugs. B13's 92% figure is definitionally inflatable.",
      "java_bias": "Yuan's sample 4/5 Java (Hadoop). Our bugs span Go (etcd), Go (CockroachDB), C (Redis-Raft) — broader.",
      "hotos_2019": "Azure study found data-format bugs at 21% — absent from both Yuan and our Jepsen sample."
    }
  },
  "b14_status_change": "theorized → PARTIAL",
  "b14_justification": "Node-count ≤3 CONFIRMED analytically (4-5/5). Determinism 60-80% brackets 74%. Full OBSERVED requires Docker 3-node reproduction.",
  "lesson": "L-642",
  "next_steps": [
    "Reproduce Redis-Raft #14 and #19 in Docker 3-node setup (deterministic, low complexity)",
    "CockroachDB #9083: verify marginal 3-node finding with controlled clock skew",
    "Measure Jepsen 5-node vs 3-node detection rate across all published Jepsen analyses",
    "Scope HQ-5 down: only etcd-11456 and redis-raft-17 strictly need iptables partitions"
  ]
}
