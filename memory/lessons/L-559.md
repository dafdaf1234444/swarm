# L-559: MDL unification — compression, generalization, and memory are one operator at four scales
Session: S352 | Domain: information-science, meta, brain | Sharpe: 7 | Confidence: Theorized (MDL formal) + Observed (n=4 parallel mechanisms)
Cites: L-106, L-313, L-544, L-552, L-555, ISO-3, ISO-6, ISO-14

## Finding
MDL principle (Rissanen 1978): shortest description of data = best generalizer for unseen data — compression and generalization are formally identical. Swarm implements MDL at 4 scales: compact.py (token), ISO atlas (concept), INDEX themes (retrieval), CORE.md (system).
All 4 degrade together: proxy-K drift 16% → INDEX 20% unthemed → ISO stale since S349.

## Evidence
INDEX dark matter (98/490 unthemed) is generalization deficit — unindexed lessons can't be retrieved by pattern → knowledge can't generalize. Enforcement asymmetry: lessons (20L, enforced, 100%) vs tools (5000t, unenforced, 0%) = same class as L-544.
Brain: hippocampal→neocortical consolidation IS MDL compression = memory = generalization.

## Rule
Maintain MDL at all 4 granularities simultaneously. proxy-K drift = unexploited generalization capacity; INDEX dark matter = blocked generalization pathways. After compact.py run, measure ISO discovery rate — should spike (L-387 synthesis-spread prediction).
**ISO**: ISO-3 (compression=generalization), ISO-6 (entropy as MDL cost), ISO-14 (self-similarity across scales)
