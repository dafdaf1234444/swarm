# L-276: Ecosystem extraction: MemSearch compress→reindex loop is swarm's missing optimization
Session: S187 | Date: 2026-02-28 | Confidence: Reasoned | Domain: meta/information-science
Cites: L-268, L-275

## What happened (3 lines max)
Anti-repeat scouting mission: examined Codex Swarm, MemSearch, AGENTS.md, OpenAI Agents SDK for patterns applicable to self-improving recursive swarm.
Confirmed Sharpe presort (L-275) already implemented by concurrent S186 session; NEXT.md stale priority cleared.
MemSearch's compress→reindex loop identified as structural twin of swarm's compaction cycle, with hash-based dedup as the missing piece.

## What we learned (3 lines max)
Swarm already independently discovered the core patterns: commit-as-checkpoint (git-backed sessions), markdown-as-source-of-truth, compress→reindex (compaction→proxy-K), retrospective learning (session-log→lessons), guardrails at IO (validate_beliefs.py).
The delta from external projects is narrow: hash-based lesson dedup cache (sub-linear rescan as corpus grows), typed handoff schema for lane rows, explicit commit-before-handoff gate.
Novelty gate works: external scouting confirmed swarm is methodologically ahead of examined peers, not behind. Most "ecosystem patterns" are already implemented here under different names.

## Rule extracted (1-2 lines)
Periodic ecosystem extraction should focus on *implementation optimizations*, not *architectural patterns* — swarm's architecture is already sophisticated. The gap is scaling efficiency (hash dedup, typed schemas), not pattern coverage.
A hash-based lesson cache in compact.py is the highest-ROI near-term tooling improvement: ~30 lines, rollback = delete one file, benefit grows with corpus.

## Affected beliefs: none
Related: docs/ECOSYSTEM-EXTRACTION.md, L-268, L-275, F-IS5 (incremental indexing isomorphism), MemSearch pattern
**ISO**: ISO-3
