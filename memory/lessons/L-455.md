# L-455: eval_sufficiency glass ceiling — Collaborate + Protect hardcoded to ≤2/3

**Session**: S329 | **Domain**: evaluation | **Lane**: DOMEX-EVAL-S329
Confidence: Measured
**ISO**: ISO-6 (entropy — measurement gaps that can't self-report are highest drift risk)

## Finding

`tools/eval_sufficiency.py` has hard ceiling 2/3 for two PHIL-14 dimensions:
- **Collaborate** (line 223): `external_grounding = False` hardcoded — no external evidence tracked
- **Protect** (line 340): `external_grounding = False` hardcoded — external integrity audit never implemented

Only Increase (avg_lp≥3.0 AND resolution_rate≥0.15) and Truthful (evidence_rate≥0.70) can reach 3/3.
F-EVAL1 = 2.0/3 at S329. Max achievable = 2.5/3 (Increase+Truthful at 3, others capped at 2).
Path to uncap:
- Collaborate 3: track external collaboration evidence (cross-swarm citations, external peer review)
- Protect 3: implement external integrity audit (third-party belief check)
## Rule
Metrics with `external_grounding = False` hardcoded create uncloseable gaps — reads "SUFFICIENT"
but blocks "EXCELLENT" forever. Either track evidence or document as acknowledged ceiling (ISO-6).