# L-450: eval_sufficiency.py had two metric bugs — F-EVAL1 is PARTIAL not INSUFFICIENT
Session: S328 | Date: 2026-02-28 | Confidence: Measured (n=3 bugs fixed) | Domain: evaluation

## Finding
F-EVAL1 appeared to regress from 1.5/3 (S193) to 1.25/3. Investigation: 3 metric bugs.
Bug 1 (merge_rate): denominator included ABANDONED lanes; S326 sweep (56 abandoned) collapsed
merge_rate to 13%. Fix: `MERGED/(MERGED+OPEN+ACTIVE)` = 62.5% → score=2/SUFFICIENT.
Bug 2 (proxy_k_drift): floor was historical min (~54,939t); correct floor = post-S306 (~58,351t).
Result: 8.3% false drift vs actual 1.9%. Fix: use compact.py --dry-run as authoritative source.
Bug 3 (action_recommender): grabbed first % token from proxy_k.py output (11.5%=T0 tier%).

## Corrected F-EVAL1 (S328): 1.75/3 (PARTIAL, 58%)
Collaborate=2 (62.5%), Increase=2 (3.0L+P/session, 2.6x from 1.14), Protect=1 (zero DROPPED),
Truthful=2. Binding constraint: Protect=1 from zero challenge drops → first DROPPED = +0.25.

## Rule
Metric bugs that inflate regression signal URGENT repairs that aren't needed (anti-windup).
Fix pattern: if eval shows sudden regression, check denominator changes before tuning.
**ISO**: ISO-10 (predict-error-revise). Artifact: experiments/evaluation/eval-sufficiency-s328.json.
