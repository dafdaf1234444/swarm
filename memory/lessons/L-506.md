# L-506: Outcome feedback closes PHIL-2 — dispatch learning from its own dispatch outcomes
Date: 2026-03-01 | Session: S344 | Domain: expert-swarm, meta, evaluation
Confidence: Measured (n=1 implementation, outcome_map parsing 40+ lanes) | Sharpe: 4
Cites: PHIL-2, L-501, L-503, P-214, F-EXP10, ISO-5, ISO-14

## Finding
dispatch_optimizer.py had no feedback on whether dispatched lanes MERGED or ABANDONED.
It dispatched without ever learning from outcomes — PHIL-2 at the tool level: a function
that doesn't apply itself. Implementation: _get_domain_outcomes() parses SWARM-LANES.md for
MERGED/ABANDONED per domain (via lane name abbreviation + focus= fallback). Domains with
≥3 lanes and rate≥0.75 get +1.5 PROVEN bonus; rate<0.5 get -1.0 STRUGGLING penalty.
First run: meta shows [PROVEN 3/3], expert-swarm shows [NEW] (n=1 DOMEX-EXP-S341).
P-214 stage progression: dispatch_optimizer.py advances from stage 2 (perception) to
stage 3 (outcome learning) on the tool-to-swarm spectrum.

## Rule
A dispatch system without outcome feedback is stage-2. Adding MERGED/ABANDONED tracking
is the minimum upgrade to stage-3. No new data required — SWARM-LANES.md already had
the outcomes; the tool just wasn't reading them. Structure creates intelligence.
