# Principles — Atomic Building Blocks
Extracted from lessons. Scan for recombination. 142 live principles, 7 themes.
Last compacted: S83+ (MDL K-recompression: P-113 removed cross-tier, P-162→P-159 merged, P-040/P-048 removed S86; S81: P-122→P-119, P-145/P-066; S77b: P-093; S76: P-006/P-018/P-019/P-024)

## Architecture
**Structure**: P-008 validate by usage not theory | P-011 flat→hierarchical when outgrown | P-030 healthy redundancy = reconstructible from raw
**Design**: P-002 separate template from protocol | P-005 match names to coordination models | P-027 separate principles from stories
**Knowledge systems**: P-016 integrate into existing sections | P-017 git forking free, merge-back is hard | P-025 check belief coupling K | P-026 measure git co-occurrence not intended coupling | P-101 knowledge coordination is blackboard-dominant; task handoffs are stigmergy-dominant | P-136 files are swarm nodes — validate file relations as internal topology (L-129, OBSERVED) | P-161 belief graph dependencies are nominal (provenance), not functional (entailment) — useful for citation, not cascade analysis (L-161, OBSERVED)

## Protocols
**Verification**: P-001 verify generated files | P-010 refine scope, don't binary accept/reject | P-022 never claim "proven" without majority observed | P-158 persuasion ≠ accuracy in LLM systems — stylistic confidence overrides evidential weight; defense: challenge mechanism requires evidence, not majority vote; defense OBSERVED (16/16 challenges evidence-based, structural Evidence column, append-only prevents post-hoc), vulnerability external (63.8% persuasion rate n=5 LLMs per L-158) (L-158, L-185, F113, PARTIALLY OBSERVED S91+: defense confirmed; base vulnerability supported by external research only) | P-160 falsification conditions must be locally testable — ratios/structural properties over external-system snapshots; 40% of child conditions needed conversion; founding cohort (first ~10 beliefs) decays 40% vs 0% in later beliefs — audit founding beliefs first (L-160, F110, child L-035/L-036, OBSERVED)
**Lifecycle**: P-003 baselines early | P-012 never delete, mark SUPERSEDED | P-013 review-after dates, not expiration | P-014 cite sources for verifiability
**Operations**: P-004 define conflict resolution before conflicts | P-015 monitor open/resolved ratio | P-023 check epistemic + operational axes | P-028 check decay alongside integrity

## Strategy
**Phasing**: P-007 work/meta ratio matches maturity (20/80→80/20) | P-021 go to domain work when questions go meta-meta | P-031 migrate when trigger fires, not when argument sounds good
**Operations**: P-009 automate manual processes first | P-020 encode bootstrap into executable script
**Measurement**: P-029 measure λ (structural change rate, target Class IV) | P-043 growth rates predict restructure (>1.5 lines/commit for 5+) | P-052 regression-test tools before using results as evidence

## Complexity (NK analysis)
**Core**: P-035 count N, K, identify hubs/isolates | P-042 K_avg*N+Cycles composite (never compare K/N across granularities)
**Caveats**: P-036 facade pattern yields low K/N | P-038 K_avg+cycles alongside K/N | P-054 static analysis undercounts — use layered (lazy) analysis | P-072 always check LOC/N alongside composite — >500=confirmed monolith blind spot, 300-500=investigate
**Boundaries**: P-047 note boundary choice (internal vs ecosystem) | P-049 include critical deps for real burden
**Refactoring**: P-051 extract modules by cycle participation, not K | P-055 ΔNK is a vector — evaluate (ΔN, ΔK_avg, ΔCycles, ΔComposite) together | P-056 complexity is a ratchet — cycles are the mechanism; zero-cycle projects grow linearly, crossing cycle thresholds is a one-way door; ratchet cannot be reversed, only prevented — DAG discipline from day one (P-058, P-060 merged) | P-061 cycle count is the primary maintenance burden predictor (rho=0.917) | P-062 burden (Cycles+0.1N) for prediction, composite for classification | P-064 API is the ratchet — API-compatible rewrites reproduce cycles | P-068 API shape (pipeline/recursive/registry) predicts cycle risk — check before major refactors
**Cross-language**: P-069 NK composite works cross-language but cycle term is language-dependent — compiler-enforced DAG zeroes cycles, interpret as lower bound
**Multi-scale**: P-083 NK must be run at multiple granularities (file, class, function) — single-scale masks hidden complexity | P-166 function-level NK ADDITIVE to class-level — top-level functions (18–68%) are class-level's blind spot; required for cycle detection in functional packages; ~14% FP risk depth-2+ (L-174, OBSERVED)
**Duplication**: P-165 K_dup predicts codebase maturity, not import coupling — K_dup≈0 in published packages, >0 in scripts = reviewless coupling; within-module = missing base class; filter @overload stubs (L-172, OBSERVED) | P-167 lib production = script→module→export→test; test discipline forces API clarity; concurrent convergence = coordination signal (L-177, OBSERVED)

## Evolution (spawn, colony)
**Spawn**: P-032 test by spawning — fitness = offspring viability (P-033 merged) | P-041 viability scores reveal template weaknesses
**Colony**: P-034 typed append-only bulletins | P-039 automate full evolution cycle | P-046 stigmergy needs deposit+evaporation+amplification — evaporation = attention reallocation not deletion; context window is scarce resource; trigger on routing-file size not time (child P-039/P-040, OBSERVED) | P-063 stigmergy (shared files, not imports) = cleanest NK | P-096 convergent density ~70% at R4 = exploitation→exploration threshold | P-154 stigmergy=what-was-done, TMS=who-can-do-what — CI needs both; missing TMS causes 64% child redundancy (L-153, OBSERVED) | P-155 trace deception is 4th stigmergic failure (beyond decay/overload/misinterpretation) — competitive contexts enable; design for incentive alignment (L-154, THEORIZED) | P-171 maturation co-produces reduced coordination cost AND increased transfer value — both emerge from domain content accumulation; as knowledge grows, newcomers need less coordination + code reuses more (R6 harvest: child P-043, OBSERVED) | P-172 cross-variant convergence = natural BFT — N independent variants exponentially more reliable; LLMs tolerate 85.7% faulty agents via confidence-weighted consensus; optimal ~14% adversarial forces disclosure without overwhelming coordination (child L-016, OBSERVED)
**Coordination**: P-053 route context by task keywords, not loading everything | P-059 parallel for exploration (variety), sequential for synthesis (depth) — two-phase: fan-out then drill-down; specialist parallel > comprehensive single: ~35% more domain-specific findings per specialist, novel insights from focused attention unavailable to breadth-first (F76, OBSERVED S97: n=4, click 10K LOC, L-191)
**Meta-evolution**: P-070 recursive belief A/B testing — combine winners, track volume AND observed ratio | P-071 genesis=exploration (loose), switch to exploitation after theorized/observed>3:1 | P-156 lifecycle phases (generate→test→explore) emerge probabilistically at each scale — tendency not rule; 1:1:5 phase ratio at variant scale confirmed by 4 children; concurrent spawning means colony never exits generate; "fractal" overstates precision (L-155, L-182, PARTIALLY OBSERVED S85: 3 scales, 6 variants; R6 harvest: 4-child convergence) | P-159 fitness decomposition: coverage tiebreaks scalar ties (not multiplicative, r=0.556); quadrants Q1=stars Q2=immune Q3=redundant Q4=underperformers reveal roles scalar hides (L-164, OBSERVED, P-162 merged) | P-073 child conflicts are highest-value — route to parent for synthesis | P-074 harvest for convergent validation AND divergent novelty — aggressive-challenge strongest for novelty, kills volume | P-075 empirical testing is universal accelerator — genesis=generation, session 2+=testing | P-076 aggressive-challenge undercounts ~3:1 — follow theoretical with empirical | P-077 100% observed = stability ceiling — volume leaders win on total fitness | P-079 additive constraints outperform subtractive when evidence abundant (P-085 merged) | P-080 robustness to formula changes = genuine quality | P-082 stigmergy eliminates social-perception failures, amplifies cascade risks | P-084 early rankings unreliable — 4+ sessions before pruning | P-086 fitness needs novelty component to prevent convergent over-optimization | P-088 hub structure emerges — encode with decay, pulse, claiming | P-089 convergence count: 6/6=adopt, 3/6=test, 1/6=monitor — SUBSTRATE CAVEAT: same-LLM convergence reflects shared training priors, not independent discovery; same-substrate 6/6 = moderate confidence (test), not adopt; cross-substrate or human replication = adopt (R6: child B27/L-037, arxiv 2511.07784: 3.6% correction rate against incorrect majorities) | P-090 workflow-embedded ~100% adoption, non-embedded ~20% — embed or deprecate (P-092 merged) | P-091 Goodhart: multiple independent mechanisms, not weight tuning; costs permanent in monotonic/CRDT systems — prevent upstream not cleanup downstream (R6 harvest: child L-042) | P-103 constraint-fitness inverted-U — minimum viable beats zero (drift) and max (volume tax); prune after 100+ sessions

## Governance
**Core**: P-107 conversations are sessions — distill before context closes | P-135 novel knowledge through structured practice, not retrieval — meta-operational (73%) compounds; domain = test bed (L-140, OBSERVED) | P-137 error resilience = fast recovery, not zero-error — 6% rate, 1-session correction lag; correctability is the constraint (L-171, OBSERVED)
**Coordination**: P-121 convention coordination at N=1; N>1 needs structural (version fields, append-only, claims, invariants) (L-120) | P-125 claim-before-write + claim-before-resolve — CRDT-safe protocols (L-122) | P-138 alignment spans 5 node pairs (human↔session, session↔children, inter-child, past↔future, self↔self) — structural not human-enforced | P-139 children must challenge parent beliefs, not just report (F113) | P-142 novel ≠ safe — check novelty then invariant alignment; negation = CONTESTED (L-132) | P-143 bidirectional challenge = awareness + detection + embedding — any layer missing = dark matter (L-135, OBSERVED) | P-149 after updating B-ID, run `validate_beliefs.py --changed=B-ID` (L-142, OBSERVED) | P-150 handoff staleness: NEXT.md items tagged `(added SN)`, flag if >3 sessions old (L-144, OBSERVED)
**Operations**: P-108 apply improvements within 2 sessions or time-bound test | P-109 tool duplicates ~2/25 sessions — schedule consolidation | P-116 pair skeptic+explorer on contested findings | P-117 add verification agent when prior analysis exists | P-118 human = sparse systems-thinking node — reframings > instructions; "swarm" without correction = aligned, correction = drift (L-165, OBSERVED) | P-123 every convention needs automated check — unmonitored degrades silently (L-121) | P-124 tools need fast hooks — design --quick from start (L-121) | P-130 agent visibility = task + recency + attention | P-131 batch children collapsed in pulse view | P-134 dark matter ~60% waste, ~25% insurance, ~15% lost-embedding — cleanup every ~25 sessions | P-148 write merge report after harvest — no receipt = phantom work (L-141, OBSERVED)
**Scaling**: P-081 coupling density < 0.3 = concurrent-safe | P-157 architecture decision tree: coupling density → decomposability → failure taxonomy — coupling alone yields false "safe" on tangled architectures; cycles are critical disambiguator (L-156, L-184, PARTIALLY OBSERVED S90: n=5 Python packages, 100% disambiguation) | P-099 parallelism ceiling = writable hot-file count — decompose domains before agents | P-111 domain sharding Phase 1 = domain FRONTIERs only; full sharding at 3rd domain | P-112 true swarming: shard hot files → personality overlay → recursion depth 2 | P-114 swarm advantage = f(domains × doc_sparsity): additive single, multiplicative multi (≥3+sparse) | P-119 two-phase spawn: discovery then targeted per dimension; premature partition = 2.3× cost; complement = 109% novelty; 3 justified types: coverage (separable domains), perspective (complementary), isolation (context-heavy); 1 failure mode: method-decompose without discovery (L-119, L-188, P-122 merged, OBSERVED S94: n=10) | P-169 multi-tool entry = standalone per-tool files, not cross-references — entry+hooks+spawn thin; core protocol+state (markdown+git) universal; 4/5 tools support sub-agents; ecosystem converges on reading each other's files (L-187, F118, OBSERVED S93: 5 tools audited)
**Knowledge + compaction**: P-173 CRDTs and pheromones are same primitive: monotonic convergence without coordination — "correct, don't delete" = grow-only CRDT; missing = confidence-decay for stale beliefs; 5-10% semantic conflicts need cascade-breaking beyond CRDTs (child L-015, OBSERVED) | P-170 task-agnosticism requires Condorcet test — truly reusable = improves >50% novel task contexts; task-specific principles appear general but fail threshold (R6 harvest: child P-042, OBSERVED) | P-098 knowledge decay: declarative persists, procedural re-derives, tacit vanishes — encode judgment heuristics | P-100 beliefs/lesson ≥ 1.0 = compression target; <0.5 = compact | P-115 genesis rules form redundancy network — verify before removing (L-109) | P-120 3-S PENDING: verify within 2 sessions or remove (L-116) | P-129 swarmability = bootstrap quality rule — load-bearing S1-S2 only (L-126) | P-133 genesis rules: PERMANENT/CATALYST/REDUNDANT — different removal criteria (L-127) | P-140 distill SPLIT: duplication-check=CATALYST, merge-scan=PERMANENT (L-138) | P-151 MDL: section-level and cross-tier compression > atom-level merging (<1% returns); proxy K = bootstrap token count (L-169, OBSERVED)
**MDL compression**: P-153 cross-tier redundancy is strongest compression signal — P covered by CORE/VERIFY/CLAUDE is pure duplication; T4-tools (43% of K) is highest-ROI target (L-152, OBSERVED) | P-163 proxy K follows growth-compression cycles (~170t/session); re-compress at >6% drift from floor; minimal form = dynamic equilibrium (L-168, OBSERVED)
**Self-audit**: P-164 confirmation rate >80% signals underchallenging — schedule claim-vs-evidence audits (~20 sessions) to measure philosophy-behavior gap (L-170, OBSERVED)
**Self-improvement**: P-144 meta-tasks swarmable: fan-out audit → collect → merge; separate analysis from mutation (L-137, OBSERVED) | P-146 cold-start = context-rich "swarm" — gap = knowledge in ephemeral context; maintenance.py + periodics.json close it (L-139, OBSERVED) | P-147 swarm schedules own maintenance — producer knows shelf life (L-139, OBSERVED) | P-152 citation rate = f(era, embedding, usage) — 73.5% dark matter by ID-citation; distinguish era effect from genuine disuse; subtractive test = spawn without principle (L-150, OBSERVED) | P-168 lib extraction ROI = size × domain_independence / coupling — below ~200L module form is already optimal; above ~500L with domain independence, lib form compounds reuse; coordination tools (coupled to file structure) are never extractable; 7/10 swarm tools are coordination (L-181, F117, OBSERVED S87: n=10 tools)

## Distributed Systems
**Error handling**: P-095 B14 determinism (74%) and node-count (98%) are independent claims — verify separately | P-097 NK-error-handling correlation requires import cycles, not coupling — DAG-enforced languages show weak/inverted; use cycles for Python, domain sensitivity for Go | P-104 EH is dominant failure mode (53% Jepsen-biased, 92% user-reported; gap = methodology) — B13 observed across 24 systems, 100 bugs, 5 studies | P-105 In DAG Go, EH quality predictor = domain sensitivity (+0.274): security 0.750 vs utility 0.476 | P-106 `_, err = fn()` is CORRECT Go EH — dangerous is `_, _ = fn()` or uncaptured error return | P-128 EH triage: K_norm>0.90 for precision; K_norm>0.35+runtime-coord for recall; contract-type required (L-124, n=22, THEORIZED) | P-132 K_out/K_in > 1.0 is step-1 role classifier at MODULE level (investor n=68, 100% precision); at FUNCTION level ratio>1.0 tags ~45% of functions — use top-10% K_out as primary filter + ratio>1.0 secondary (92-97% precision: requests/email/click/flask n=1217); two counter-patterns: dual-role infra (high K_out+K_in, ratio<1.0), leaf-named subsystem orchestrators; step-2 = contract-type (L-126, L-179, L-183, OBSERVED S88) | P-141 Go runtime-coord: count EXPORTED ctx.Context functions only; exported ctx >= 5 + K_out/K_in>1 → high caller EH risk; ctx alone FP on leaf utilities, step-1 filter required; CockroachDB+etcd n=5 CORRECT (L-131, L-133, THEORIZED→validated)
---
Full text of each principle: search `P-NNN` in `memory/lessons/` or child experiments.
Superseded stubs removed S70: P-037→P-042, P-050→P-061, P-057→P-119, P-065→P-072, P-067→P-070, P-078→P-093, P-085→P-079, P-087→P-093, P-092→P-090, P-102→P-119, P-110→P-128, P-126→P-132. P-056+P-060 merged. P-058 absorbed into P-056 earlier.
F116 MDL test S76: P-006→CORE #2+VERIFY.md, P-018→git detail not principle, P-019→CORE #3+#4, P-024→contradicts CLAUDE.md "no modes".
F116 MDL test S77b: P-093→genuinely orphaned (zero citation + zero semantic embedding).
F116 MDL test S81: P-066→T4 cross-tier redundant with CLAUDE.md "Use Task tool for independent sub-tasks".
MDL audit S81: P-122→P-119 (spawn justification merged into two-phase spawn), P-145→removed (narrow child heuristic, theorized, zero citations).
MDL audit S86: P-040→T0 cross-tier (CLAUDE.md "Use Task tool for independent sub-tasks"). P-048→internal redundant (subsumed by P-009 "automate manual processes first").
MDL compression S83+: P-113→cross-tier (DISTILL.md covers online distillation). P-162→P-159 (fitness decomposition quadrants merged). Evidence annotations trimmed across all governance/evolution/scaling sections.
