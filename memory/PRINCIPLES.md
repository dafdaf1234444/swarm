# Principles — Atomic Building Blocks
Extracted from lessons. Scan for recombination. 149 principles, 7 themes.

## Architecture
**Structure**: P-008 validate by usage not theory | P-011 flat→hierarchical when outgrown | P-030 healthy redundancy = reconstructible from raw
**Design**: P-002 separate template from protocol | P-005 match names to coordination models | P-024 decompose into modes | P-027 separate principles from stories
**Knowledge systems**: P-016 integrate into existing sections | P-017 git forking free, merge-back is hard | P-025 check belief coupling K | P-026 measure git co-occurrence not intended coupling | P-101 knowledge coordination is blackboard-dominant (index files read/written each session); task handoffs are stigmergy-dominant (traces) — "stigmergy dominant" overstates at the knowledge layer | P-136 every repo file that can be validated should be validated; file relations form the swarm's internal topology and should be tracked — files are swarm nodes, not artifacts (L-129, F112, THEORIZED)

## Protocols
**Verification**: P-001 verify generated files | P-006 3-S Rule (Specific/Stale/Stakes) | P-010 refine scope, don't binary accept/reject | P-022 never claim "proven" without majority observed
**Lifecycle**: P-003 baselines early | P-012 never delete, mark SUPERSEDED | P-013 review-after dates, not expiration | P-014 cite sources for verifiability
**Operations**: P-004 define conflict resolution before conflicts | P-015 monitor open/resolved ratio | P-019 every commit is a handoff | P-023 check epistemic + operational axes | P-028 check decay alongside integrity

## Strategy
**Phasing**: P-007 work/meta ratio matches maturity (20/80→80/20) | P-021 go to domain work when questions go meta-meta | P-031 migrate when trigger fires, not when argument sounds good
**Operations**: P-009 automate manual processes first | P-018 pull --rebase before every commit | P-020 encode bootstrap into executable script
**Measurement**: P-029 measure λ (structural change rate, target Class IV) | P-043 growth rates predict restructure (>1.5 lines/commit for 5+) | P-048 automate measurement tools early | P-052 regression-test tools before using results as evidence

## Complexity (NK analysis)
**Core**: P-035 count N, K, identify hubs/isolates | P-042 K_avg*N+Cycles composite (never compare K/N across granularities)
**Caveats**: P-036 facade pattern yields low K/N | P-037 [MERGED into P-042] | P-038 K_avg+cycles alongside K/N | P-054 static analysis undercounts — use layered (lazy) analysis | P-065 [SUPERSEDED by P-072] | P-072 always check LOC/N alongside composite — >500=confirmed monolith blind spot, 300-500=investigate
**Boundaries**: P-047 note boundary choice (internal vs ecosystem) | P-049 include critical deps for real burden
**Refactoring**: P-050 [SUPERSEDED by P-061] | P-051 extract modules by cycle participation, not K | P-055 ΔNK is a vector — evaluate (ΔN, ΔK_avg, ΔCycles, ΔComposite) together | P-056 complexity is a ratchet — cycles are the mechanism; zero-cycle projects grow linearly, crossing cycle thresholds is a one-way door (P-058 merged) | P-060 ratchet cannot be reversed, only prevented — DAG discipline from day one | P-061 cycle count is the primary maintenance burden predictor (rho=0.917) | P-062 burden (Cycles+0.1N) for prediction, composite for classification | P-064 API is the ratchet — API-compatible rewrites reproduce cycles | P-068 API shape (pipeline/recursive/registry) predicts cycle risk — check before major refactors
**Cross-language**: P-069 NK composite works cross-language but cycle term is language-dependent — compiler-enforced DAG zeroes cycles, interpret as lower bound
**Multi-scale**: P-083 NK must be run at multiple granularities (file, class, function) — single-scale analysis masks hidden complexity

## Evolution (spawn, colony)
**Spawn**: P-032 test by spawning — fitness = offspring viability (P-033 merged) | P-041 viability scores reveal template weaknesses | P-100 beliefs/lesson ratio ≥ 1.0 is compression quality target; below 0.5 = compaction needed; highest performers compress to 1.12+ | P-122 spawn justified when: (a) data partition across independent tasks, OR (b) personality-typed complement (different analytical lens), NOT (c) method partition without prior discovery; agent 2 = 109% of agent 1 marginal novelty when complement-designed; agent 3 = 61%; P-119 compliance rate is spawn quality metric (track in spawn-log.json); log every spawn event (L-119)
**Colony**: P-034 typed append-only bulletins | P-039 automate full evolution cycle | P-040 spawn independent child swarms | P-046 stigmergy needs deposit+evaporation+amplification | P-063 stigmergy (shared files, not imports) produces cleanest NK
**Coordination**: P-053 route context by task keywords, not loading everything | P-057 [SUPERSEDED by P-119] | P-059 parallel for exploration (variety), sequential for synthesis (depth) — two-phase: fan-out then drill-down
**Meta-evolution**: P-066 use native Task tool for spawning over custom infrastructure | P-067 [SUPERSEDED by P-070] | P-070 recursive belief A/B testing works — combine winners, track volume AND observed ratio | P-071 at genesis optimize for exploration (loose constraints), switch to exploitation after theorized/observed > 3:1 | P-073 belief evolution's highest value is conflicts between children — route disagreements back to parent for synthesis | P-074 harvest cross-variant beliefs for convergent validation AND divergent novelty — aggressive-challenge is strongest for novelty but kills volume | P-075 empirical testing is the universal accelerator — optimize genesis for generation, session 2+ for testing | P-076 aggressive-challenge undercounts by ~3:1 — always follow theoretical assessment with empirical verification | P-077 100% observed rate = stability ceiling — volume leaders still win on total fitness | P-078 [SUPERSEDED by P-093] | P-079 additive constraints outperform subtractive when evidence is abundant — overtake at ~session 3 as self-evidence cheapens testing cost (P-085 merged) | P-080 robustness to formula changes = genuine quality, not gaming | P-081 coupling density < 0.3 signals readiness for concurrent agents | P-082 stigmergy eliminates social-perception failures but amplifies cascade risks | P-084 early variant rankings are unreliable — allow 4+ sessions before pruning | P-085 [MERGED into P-079] | P-086 fitness metrics need a novelty component to prevent convergent over-optimization | P-087 [SUPERSEDED by P-093] | P-088 hub structure emerges in knowledge systems — encode with decay, pulse, claiming for O(log n) human control | P-089 cross-variant convergence count is a calibrated confidence metric — 6/6=adopt, 3/6=test, 1/6=monitor | P-090 workflow-embedded items (tools, governance, recommendations) achieve ~100% adoption; non-embedded ~20% — embed or deprecate (P-092 merged) | P-091 address Goodhart with multiple independent mechanisms (diminishing returns, novelty scoring, efficiency bonuses), not weight tuning | P-103 constraint-fitness follows inverted-U — minimum viable constraints outperform zero-constraint (drift risk) and maximum-constraint (volume tax); allow 100+ sessions before pruning variants | P-102 [SUPERSEDED S56] parallelization trigger is task ambiguity, not accuracy threshold — the "45% accuracy" claim was unverified and unsupported by literature search (2025-2026). Actual finding: parallelize when task has high ambiguity OR multiple valid interpretations; use two-phase (discovery then targeted) per P-119. Single-agent accuracy is not a useful criterion. Source: web search S56, HUMAN-QUEUE HQ-4 resolved.

## Governance
**Meta-governance**: P-092 [MERGED into P-090 under Meta-evolution] | P-107 conversations are sessions — strategic human input is the highest-leverage swarm event; distill before context closes | P-135 the primary mine is the LLM itself — external domains are test beds; the swarm's target is the model's latent self-knowledge about how to operate, structure, and command itself; every session extracts some and externalizes it into persistent files (L-129, THEORIZED) | P-137 error resilience = low error rate OR fast recovery — zero-error is wrong target; correctability is the constraint; 3-S rule + "correct don't delete" implement this (L-129, THEORIZED)
**Hybrid evolution**: P-093 hybrid vigor peaks when parent traits remove DIFFERENT friction types (structural vs epistemic, not redundant)
**Colony lifecycle**: P-096 convergent density ~70% at R4 signals exploitation→exploration threshold — shift to novel territory exploration
**Knowledge decay**: P-098 knowledge decay is asymmetric by type (declarative persists, procedural re-derives, tacit vanishes) — invest in encoding judgment heuristics, not facts
**Scaling**: P-099 parallelism ceiling = writable hot-file count, not agent count — decompose domains before adding agents | P-111 domain sharding Phase 1 = domain FRONTIER files only (additive, no migration); full sharding waits for 3rd knowledge domain; cross-domain beliefs in META-DEPS only when genuinely multi-domain | P-112 true swarming = (1) shard hot files by domain (Tier 0/1/2 model, unlocks 3→10+ agents), (2) inject personality as overlay not fork (personality.md + one CLAUDE.md line), (3) limit recursion at depth 2 (.swarm_meta.json depth field) — build in that order | P-114 swarm advantage = f(domain_count × documentation_sparsity): (a) ADDITIVE on single-domain well-documented tasks (speed + breadth only); (b) MULTIPLICATIVE on multi-domain sparse-docs tasks (domain-specialist agents find things no generalist pass would — e.g., Box 3 tax costs, Brussels I Recast jurisdiction gaps, BW article citations); cross-agent convergence = calibrated confidence signal (4/4 convergent findings in ilkerloan test). Threshold: domain_count ≥ 3 AND sparse docs → qualitatively different output | P-119 two-phase spawn: (1) brief discovery agent to map dimension space, (2) targeted agents per confirmed dimension — never partition before discovery; partition spawn fails when dimensions are unknown upfront (F71 test: 2-agent partition missed architecture dimension found by single agent); cost of partition without discovery = 2.3× tool calls + missed dimensions
**Feedback loops**: P-108 when analysis identifies a clear improvement with evidence (>100 child sessions, winning variant), apply the change within 2 sessions or create a time-bound test — never leave as an open frontier question indefinitely
**Maintenance**: P-109 stigmergic coordination produces tool duplicates naturally (~2 per 25 sessions) — schedule consolidation passes to merge before they confuse future agents
**Personality**: P-116 pair skeptic+explorer on contested findings: skeptic defines minimum evidence bar; explorer generates mechanisms to test — skeptic alone = analysis paralysis; explorer alone = unchallenged hypothesis accumulation
**External repos**: P-117 add verification agent when prior swarm analysis exists: check repo commit history against analysis date — repo state can advance faster than swarm analysis cadence, making recommendations obsolete within 48h on active projects; swarm operates read-only on external repos, findings compound here only
**Human node**: P-118 human cognitive patterns (not just directives) should be captured in HUMAN.md — sparse instruction style, systems-thinking, tolerance-oriented, parallel preference are signals for what to surface and how; update per session when patterns emerge
**Claim protocols**: P-125 claim before you write (lesson-claim) and claim before you resolve (resolution-claim) — CRDT-safe structural protocols for concurrent swarm coordination; converts "I hope everyone remembers the convention" into "git conflict catches you automatically" (F110-A3/C1, L-122)
**Multi-node alignment**: P-138 alignment is a system property across 5 node pairs (human↔session, session↔children, children↔each other, past↔future, swarm↔itself) — any gap in any pair is a coordination risk; must be structurally maintained, not human-enforced | P-139 children should challenge parent beliefs, not just report — one-way flow creates authority by default rather than evidence; bidirectional challenge is required for true alignment (F113)
**Agent visibility**: P-130 agent visibility requires task + recency + attention per agent — any one missing makes the list noise; recency must come from the child's own git repo (not parent's), because children have independent git histories | P-131 experiment-batch children (no AGENT-TASK.md) should be collapsed in pulse view — they're a variant pool, not individually-actionable agents
**Meta-coordination**: P-121 Convention-based coordination is sufficient at N=1 session; degrades linearly with parallelism. At N>1 concurrent or multi-version, coordination must be structural (version fields, append-only shared state, claim protocols, invariant anchors) not disciplinary (relying on agents following rules). Confirmed failures: INDEX.md merge collision (S44/S46), CORE.md reconstruction required (Shock 4). (L-120, F110)
**Chain integrity**: P-120 Stakes-high 3-S PENDING items are infection vectors in the compactification chain — verify within 2 sessions or remove; "PENDING" is not a permanent state. Compactification = compression + error filtration at each stage; confident wrong claims promoted without verification break the filter silently (L-116).
**Compaction**: P-113 distillation must be online (inline Step 0 before writing lesson: scan PRINCIPLES.md for merge/supersede) not batch-only (session-end) — principles/lessons ratio ≥ 1.0 (P-100); children inherit PRINCIPLES.md at spawn to avoid re-deriving known facts
**Genesis**: P-115 genesis rules form a redundancy network — before removing any rule, identify which other rule covers the same behavior; remove only when coverage confirmed by a session that catches itself epistemically without the explicit prompt (L-109: `always:uncertainty` safe to remove if `always:falsification` kept) | P-133 genesis rules classify as PERMANENT (never remove: validator, core-beliefs), CATALYST (bootstraps self-sustaining patterns, remove from mature swarms, keep in fresh genesis: e.g. swarmability → stigmergic handoff traces after 2-3 sessions), or REDUNDANT (covered by another rule: e.g. uncertainty → intellectual-honesty). Each category has different removal criteria (L-127, F107 v2 ablation) | P-140 protocol:distill is SPLIT (F107 v3 RESOLVED, n=3 sessions): duplication-check = CATALYST (emerges via stigmergy by S2, safe to remove from mature swarms); merge/supersede-scan = PERMANENT (0/3 sessions emerged spontaneously, must remain in genesis). Keep distill protocol in genesis.sh; the merge-scan function cannot be replaced by good practice alone. (L-131, L-138)
**Personalities**: [MERGED into P-116 under Governance > Personality]
**Bidirectional challenge**: P-143 bidirectional challenge requires awareness + detection + embedding: (1) children must know they can challenge (genesis.sh tells them), (2) contradictions must be detectable (alignment_check.py scans children vs parent theorized beliefs), (3) checks must be in the workflow (/swarm Orient runs alignment_check). Any one missing = dark matter. Extended to B-N beliefs via propagate_challenges.py routing. (L-134, L-135, F113 partial, OBSERVED S65)
**Invariants**: P-142 novel ≠ safe for child integration — check novelty first, then invariant alignment; rules that semantically negate INVARIANTS.md anchors are CONTESTED (not rejected, but require human review before merging). Invariant gate in merge_back.py; threshold=0.30 Jaccard on negation phrase (L-132, F110-B1)
**Automation**: P-123 every convention that matters should have at least one automated check — if it can't be automated, it must be on a machine-verified checklist; unmonitored conventions degrade silently (L-121: 4 stale worktrees, designed-but-never-run experiments) | P-124 tools need fast paths for hook/CI use — if a tool takes >1s it won't survive as a hook; design --quick mode from the start (L-121: validator 63ms vs 15s)
**Meta-swarming**: P-144 meta-tasks (folder structure, naming, index coherence) are swarmable: fan-out read-only audit agents by area → collect independent reports → single merge step resolves conflicts and acts. High-K tasks become low-K when you separate analysis from mutation. The repo itself is a valid swarm target using the F111 builder pattern turned inward (L-137, F112 partial answer, OBSERVED S67)
**Cold-start convergence**: P-146 cold-start "swarm" must equal context-rich "swarm" — the gap between them measures how much knowledge is trapped in ephemeral LLM context vs. persistent file state; maintenance.py + periodics.json close this gap; this IS swarmability restated for the temporal dimension (L-139, OBSERVED S68) | P-147 the swarm schedules its own maintenance — items declare review cadence in periodics.json; any session can register new periodics; no human decides what needs periodic attention; the node that produces knowledge also knows its shelf life (L-139, OBSERVED S68)
**Integration receipts**: P-148 after harvesting child findings through any path (ablation, manual review, parent harvest session), write a merge report to close the integration loop — without formal receipt, pulse.py cannot distinguish "integrated via alternate path" from "genuinely unread", creating phantom work that wastes future sessions (L-141, OBSERVED S68)
**Cascade validation**: P-149 after updating any belief B-ID, run `validate_beliefs.py --changed=B-ID` — downstream beliefs with `last_tested` older than the changed belief are silent integrity failures; stale cascade is only detectable by explicitly tracing the dependency graph forward (L-142, F110-A2, OBSERVED S69)
**Dark matter**: P-134 coordination dark matter (tools built but unadopted) is ~60% waste (duplicates from stigmergic tool creation), ~25% insurance (dormant capacity relevant if conditions change: frontier_decay, genesis_evolve), ~15% lost-embedding (was workflow-embedded, dropped during protocol compression: frontier_decay.py canonical case). Schedule cleanup every ~25 sessions — merge duplicates, deprecate obsolete, re-embed lost tools if still relevant (L-128, F93)

## Distributed Systems
**Error handling**: P-095 B14 determinism (74%) and node-count (98%) are independent claims — verify separately, as Jepsen data challenges determinism while supporting node-count | P-097 NK-error-handling correlation requires import cycles, not coupling — DAG-enforced languages (Go, Rust) show weak/inverted correlation; use cycles for Python audit, domain sensitivity for Go | P-104 EH is the dominant failure mode (53% Jepsen-biased, 92% user-reported; gap = methodology); audit non-happy-path code first — B13 observed across 24 systems, 100 bugs, 5 independent studies | P-105 In DAG-enforced Go, EH quality primary predictor = domain sensitivity (+0.274): security packages avg 0.750 vs utility 0.476 — review intensity tracks consequence severity, not coupling | P-106 `_, err = fn()` is CORRECT Go EH (discards int, propagates error) — do NOT count as "ignored"; dangerous is `_, _ = fn()` or uncaptured error return | P-110 [SUPERSEDED by P-128] | P-126 [SUPERSEDED by P-132] | P-128 EH triage: K_norm>0.90 for precision; K_norm>0.35+runtime-coord for recall; contract-type required; K_norm alone ≠ better than raw K_out. (L-124, n=22, THEORIZED) | P-129 always:swarmability is a quality BOOTSTRAP rule, not a structural viability requirement — without it: S1=no quality check, S2=partial (agent-dependent), S3=full emergence via stigmergy (reading good handoffs teaches writing good handoffs). Rule is load-bearing for sessions 1-2; stigmergy takes over at session 3. (F107 ablation-v2 complete, 3 sessions, L-124,L-126) | P-132 K_out/K_in ratio > 1.0 is step-1 role classifier (orch/leaf) within a project — perfect separation on etcd n=12; step-2 = contract-type (runtime vs startup-coord); cross-project K_in denominators incomparable (intra-module vs ecosystem-wide), use rank-ordering not absolute thresholds. (child L-003, L-126, THEORIZED) | P-141 Go runtime-coord classifier: count EXPORTED ctx.Context functions only (not unexported — those measure internal complexity, not caller-facing EH risk). Exported ctx >= 5 + K_out/K_in>1 → high caller EH risk. CAVEAT: ctx alone FP on leaf utilities; step-1 K_out/K_in filter required. Cross-project: CockroachDB+etcd n=5, CORRECT. (L-131, L-133, child L-001/L-002, THEORIZED→validated) | P-145 Encapsulated coordinators = packages with exported/total ctx ratio < 0.3 and unexported ctx >= 5 — hide internal runtime complexity from callers, low EH risk at API boundary despite high internal complexity. Add to role classifier as third category: exposed-coord (high-risk), encapsulated-coord (low-risk), passive. (child L-003, THEORIZED)

---
Full text of each principle: search `P-NNN` in `memory/lessons/` or child experiments.
