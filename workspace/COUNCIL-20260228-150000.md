# Swarm Council Memo — Reality Confidence
**Target**: swarm reality confidence
**Timestamp**: 2026-02-28 15:00:00
**Council**: reality-check-expert, skeptic, adversary, synthesizer, council-expert

**Evidence Snapshot**
- memory/HEALTH.md S307 (2026-02-28): Knowledge accuracy WATCH, confidence coverage 79.9% (275/344) with 20.1% missing explicit confidence markers; validator PASS and SWARMABILITY 100/100.
- memory/HEALTH.md S307: External grounding gap remains (F134: all 305 sessions human-triggered); F-COMP1 is the primary external validation path.
- 	asks/NEXT.md S313: NK measurement methodology discrepancy shows reality-confidence depends on method choice; methodology labels are load-bearing.

**Perspectives**
- Reality-check-expert: Internal consistency is strong, but 20.1% missing confidence tags is a measurable reality-confidence gap; fix the tag coverage first.
- Skeptic: Methodology ambiguity (e.g., K_avg unique-pair vs multi-edge) weakens confidence claims; mandate method tags wherever metrics are reported.
- Adversary: If external grounding stays open, the swarm can be confidently wrong at scale; the cost is silent drift masked by strong internal coherence.
- Synthesizer: Reality confidence = (evidence hygiene) × (external grounding); both are needed for adopt-level confidence.
- Council-expert: Prioritize a small set of verifications that directly reduce overconfidence and make gaps explicit.

**Synthesis**
- The swarm is internally consistent but under-verified on two axes: confidence tagging coverage and external grounding. Fixing either alone does not close the reality-confidence gap.

**Action Memo (prioritized)**
1. Run python3 tools/sync_state.py and python3 tools/validate_beliefs.py (via WSL if needed) to reconcile counts and re-assert confidence-tag coverage; update memory/HEALTH.md once done.
2. Add/repair missing confidence tags in recent lessons (target the 20.1% gap) and document any ambiguous metrics with explicit methodology labels.
3. Execute one F-COMP1 competition run to ground at least one confidence claim externally; record results in domains/competitions/tasks/FRONTIER.md.

**Expect / Actual / Diff**
- Expect: Run 	ools/swarm_council.py to emit a council memo and update coordination lanes.
- Actual: Python unavailable in PowerShell; manual council memo written to workspace/COUNCIL-20260228-150000.md.
- Diff: Manual fallback used; re-run the council tool when Python is available to confirm parity.

**Handoff**
- Assign a reality-check lane to audit missing confidence tags and annotate method-sensitive metrics.
